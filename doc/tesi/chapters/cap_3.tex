% !TEX root=../index.tex

\chapter{L'Algoritmo di Allenamento: Adaboost}
\label{chap:adaboost}
    \section{\emph{Ensamble Supervised Learning}}
    \label{sec:supervised_ensamble_learning}
        L'algoritmo di \emph{machine learning} utilizzato dal Zhu e Wong in \cite{Zhu13} è chiamato \emph{Adaboost}, appartenente alla famiglia degli algoritmi di allenamento supervisionati, in particolare a quella degli \emph{ensamble learner}.

        \subsection{Apprendimento Supervisionato}
        \label{sub:supervised_learning}
            \subsubsection{Definizione}
                Gli algoritmi di apprendimento supervisionato funzionano attraverso l'utilizzo di un insieme di allenamento, ovvero un insieme i cui elementi sono formati da coppie di oggetti e le relative etichette.

                \begin{equation}
                    \label{subeq:training_set_labelled}
                    T = \left\{(x_1, y_1), \cdots, (x_n, y_n)\right\} 
                    \text{ con } 
                    y_1, \cdots, y_n \in L = \left\{l_1, \cdots, l_k, \cdots \right\}
                \end{equation}

                Esiste una funzione $f$ che associa ad ogni elemento $x$ l'etichetta $y$ corretta, ovvero in modo tale che:

                \begin{equation}
                    \label{subeq:unknown_function}
                    f:Dom(f) \rightarrow L | \forall x \in Dom(f), (x, f(x)) \in T
                \end{equation}

                Se l'insieme $L$ delle etichette è costituito da un numero finito di elementi ($L = \{l_1, \cdots, l_k\}$), allora il problema dell'associazione oggetto-etichetta, prende il nome di problema di \emph{classificatore} e la funzione $f$ sarà il relativo classificatore reale.
                
                L'obiettivo dell'apprendimento supervisionato è quello di trovare la \emph{migliore} funzione $h$ che approssima il classificatore reale, essendo sconosciuto.

                L'algoritmo di apprendimento cerca la funzione $h$, chiamata \emph{ipotesi}, all'interno dello \emph{spazio delle ipotesi} $\mathcal{H}$, scegliendo quella in grado di fornire le prestazioni migliori, sia rispetto agli elementi dell'insieme di allenamento, che rispetto ad altri elementi aggiuntivi\footnote{Si costruisce anche un insieme di testing per la valutazione delle prestazioni. Per non appesantire eccessivamente la lettura, i dettagli riguardo al testing vengono omessi ad un livello di trattazione così generale. Si faccia riferimento alla sottosezione \ref{sub:dataset_di_validazione} per ulteriori chiarimenti.}.
                Si considera una ipotesi $h$ una buona \emph{generalizzazione} di $f$, quando riesce ad etichettare correttamente anche nuovi oggetti.

                Molto spesso la funzione di classificazione reale $f$ non dipende strettamente dall'oggetto $x$, ma è costituita da un \emph{processo stocastico}: in tal caso, ciò che l'algoritmo deve apprendere è una \emph{distribuzione di probabilità condizionale} $P(Y|x)$.

                \begin{equation}
                    \label{subeq:stochastic_hypotesis_choice}
                    h^* = \argmax{h \in \mathcal{H}}{P(h | data)}
                \end{equation}

                La scelta del corretto spazio delle ipotesi è fondamentale.
                È necessario trovare un compromesso tra l'\emph{espressività delle ipotesi} nello spazio $\mathcal{H}$ e la \emph{complessità computazionale della scelta di una buona ipotesi}.
                Complessivamente, il tempo di calcolo dell'allenamento, tende ad aumentare molto velocemente all'aumento della \emph{dimensione} dello spazio $\mathcal{H}$ e della \emph{complessità computazionale} nel calcolo da ogni singola ipotesi.  

            \subsubsection{Esempi di \emph{Supervised Learning}}
            \label{subsub:supervised_learning_examples}
                Esistono molti algoritmi di apprendimento supervisionato.
                Alcuni dei più famosi sono l'\emph{apprendimento di alberi decisionali}, l'\emph{addestramento su reti neurali} e le \emph{support vector machine}.

                Nell'apprendimento di alberi decisionali, definito un insieme di allenamento (\ref{subeq:training_set_labelled}) ed una collezione di \emph{attributi} valutabili sugli oggetti di tale insieme, si costruisce l'albero ramo per ramo, associando alla valutazione di ogni attributo il risultato più probabile.
                Più nel dettaglio, se l'insieme degli esempi di allenamento non è vuoto, se la classificazione su tali esempi non è sempre la stessa e se l'insieme degli attributi valutabili non è vuoto, allora si seleziona l'attributo più \emph{importante}\footnote{Minore è l'\emph{entropia} correlata all'attributo, maggiore è la sua \emph{importanza}. Nella teoria dell'informazione, ci si riferisce al concetto di \emph{entropia di Shannon}, ovvero alla misura dell'incertezza su una variabile aleatoria.
                Per una variabile aleatoria $V$ con $v_1,\cdots, v_k$ possibili valori, ognuno con probabilità $P(v_i)$, l'entropia relativa a $V$ sarà $H(V) = \sum_{i = 1}^{k}P(v_i)\log_2\frac{1}{P(v_i)} = - \sum_{i = 1}^{k}P(v_i)\log_2P(v_i)$}.
                Si valuta l'attributo su tutti gli esempi di allenamento e, per ogni valore che esso assume, si partiziona l'insieme di allenamento stesso in base a tale valore.
                Per ogni partizione, si allena un sottoalbero utilizzando la stessa procedura, prendendo in considerazione però, la collezione degli attributi privata dell'attributo appena valutato.

                Una rete neurale è una particolare struttura decisionale che ricorda la struttura neurale del cervello umano.
                Come una qualsiasi rete è rappresentabile con un grafo, in cui i nodi sono detti \emph{units} e gli archi \emph{links}.
                Un generico link dall'unità $i$ all'unità $j$ propaga l'attivazione $a_i$ dai due nodi. Ad ognuno di essi è inoltre associato un \emph{peso} $w_{ij}$, che denota la forza ed il segno della connessione.
                L'unità $j$-esima, calcola innanzitutto la combinazione lineare dei segnali in input e dei rispettivi pesi, quindi, in prossimità del valore ottenuto, calcola il risultato della \emph{funzione di attivazione} (\ref{subeq:activation_function}).
                \begin{equation}
                    \label{subeq:activation_function}
                    a_j = g(in_j) = g\left(\sum_{i = 0}^{n}w_{ij}a_i\right)
                \end{equation}
                La definizione delle funzioni di attivazione è un parametro progettuale relativo alla rete da compiere a priori dell'allenamento: a seconda del particolare obiettivo che si vuole perseguire, si sceglie una struttura neurale piuttosto che un'altra.
                In fase di allenamento, invece, si procede determinare il valore ottimo di ciascun peso relativo agli archi della rete: dato un insieme di allenamento, si cerca di mappare nel modo migliore possibile ciascun input al relativo valore di output.

                Le \emph{Support Vector Machine} (SVM) sono, attualmente, il framework di allenamento supervisionato più popolare.
                Godono di tre caratteristiche:
                \begin{enumerate}
                    \item Costruiscono un \emph{margine di separazione massimale} tra gli elementi del dataset di allenamento. Si tratta di un confine che separa gli esempi di allenamento distanziando più possibile gli elementi di classi diverse. Questa caratteristica garantisce un buon grado di generalizzazione.

                    \item Creano degli \emph{iperpiani lineari di separazione}. Elementi che non possono essere separati linearmente nello spazio originale di separazione, vengono rappresentati in spazi con un numero più elevato di dimensioni, al fine di trovare un iperpiano lineare come separatore.

                    \item Combinano i vantaggi dei metodi \emph{parametrici} e \emph{non parametrici}\footnote{I modelli \emph{parametrici} caratterizzano gli elementi di un insieme di allenamento utilizzando un numero prefissato di parametri, indipendentemente dalla cardinalità dell'insieme. 
                    Ad esempio, nelle reti neurali, il numero di pesi da fissare è una caratteristica strutturale della rete.
                    Di contro, i metodi \emph{non parametrici} non sono caratterizzati da un limite prefissato di parametri con cui caratterizzare gli esempi di allenamento.} risultando molto flessibili nella rappresentazione di funzioni di classificazione complesse, ma poco sensibili a problematiche di \emph{overfitting}.
                \end{enumerate}

            \subsubsection{\emph{Overfitting}}
                Le tecniche di addestramento supervisionato potrebbero incorrere in problemi di \emph{overfitting}.
                Dato un insieme di allenamento, infatti, la ricerca delle ipotesi che approssimano al meglio la funzione obiettivo potrebbe essere influenzata da caratteristiche che sono comuni tra gli elementi dell'insieme stesso, ma che non sono discriminanti nella descrizione più generale della classe di oggetti.

                La variabilità \emph{intraclasse} delle caratteristiche degli esempi di allenamento, viene equivocata, in fase di selezione, per variabilità \emph{extraclasse} e utilizzata, erroneamente, per la classificazione.

                Ciò porta ad un sequenziale miglioramento delle prestazioni del riconoscimento per gli elementi del dataset di allenamento, ma a prestazioni peggiori nella classificazione di nuovi elementi.

                Nella sottosezione \ref{sub:dataset_di_validazione}, verranno esposte alcune tecniche per evitare l'insorgere di problemi di overfitting.

            \subsubsection{\emph{Ensamble Learning}}
                Gli algoritmi di \emph{ensamble learning} sono una particolare categoria di algoritmi di apprendimento supervisionato.

                L'approssimazione della funzione obiettivo avviene mediante la selezione di una collezione di funzioni dallo spazio delle ipotesi.
                La predizione della classificazione dell'oggetto avviene, poi, combinando tra loro il risultato delle predizioni formulate dalle singole ipotesi.
                
                Un classificatore allenato con un algoritmo di ensamble learning, intuitivamente, fornisce previsioni più accurate, ampliando il numero di ipotesi vincenti scelte per le predizioni.

        \subsection{\emph{Adaptive Boosting}}
        \label{sub:adaptive_boosting}
            \subsubsection{\emph{Strong} e \emph{Weak Learner}}
                Di qui in avanti, si farà riferimento due tipologie distinte di classificatori, i \emph{weak learner} e gli \emph{strong learner}\footnote{Alternativamente, \emph{weak classifier} e \emph{strong classifier}.}.

                I \emph{weak learner} sono costituiti da singole ipotesi, selezionate da un qualsiasi algoritmo di allenamento supervisionato.
                La loro caratteristica principale è quella di essere meccanismi di classificazione estremamente semplici, anche dal punto di vista computazionale, e nel complesso, la loro attendibilità viene considerata di poco maggiore rispetto ad una previsione casuale.

                Gli \emph{strong learner}, invece, sono delle combinazioni di weak learner.
                Vengono definiti grazie all'implementazione di un metodo di ensamble boosting e garantiscono un'affidabilità molto maggiore rispetto ad i singoli weak learner.

            \subsubsection{Algoritmi di Boosting}
            \label{subsub:boostin_alg}
                Sono la famiglia più popolare di algoritmi che implementano l'ensamble learning.

                Inizialmente, gli algoritmi di questo tipo, associano ad un insieme di allenamento una distribuzione: ogni elemento viene caratterizzato un peso.
                Iterativamente viene selezionato, dallo spazio delle ipotesi, il \emph{miglior weak learner}, ovvero quello che riesce a classificare gli elementi del dataset compiendo meno errori possibili.

                L'idea che è alla base del successo degli algoritmi di boosting sta nel fatto che, tali pesi, vengono aggiornati per ogni elemento ad ogni iterazione in base al risultato della classificazione con il weak learner corrente. 
                Viene diminuito il peso degli elementi classificati correttamente e aumentato quello degli altri, in modo da favorire la selezione, all'iterazione successiva, di un weak learner che vada a compensare gli errori compiuti dal precedente.

                Tutti i weak learner selezionati combinano le loro singole predizioni in un'unica predizione molto accurata: lo strong learner risultante sarà la combinazione dei weak learner estratti.

            \subsubsection{Adaboost}
                Adaboost è l'algoritmo proposto da Freund e Schapire in \cite{Freund97}, ed è valso loro il premio Gödel per il contributo originale apportato al campo dell'informatica teorica.

                Il nome \emph{Adaboost} deriva dalla fusione delle parole \emph{Adaptive} e \emph{Boosting} (ed essendo un algoritmo di boosting, implementa le operazioni descritte precedentemente).

                Ciò che rende Adaboost un algoritmo di boosting \emph{adaptive} è la politica di aggiornamento dei pesi relativi agli elementi dell'insieme di allenamento: viene decrementato il peso degli elementi classificati correttamente, lasciando invariato il peso degli altri.

                Il valore di tale decremento non è costante, ma \emph{dipende dall'errore pesato di classificazione complessivo} per la relativa iterazione. 
                Maggiore è l'errore, maggiore è il decremento dei pesi.
                
                È così che Adaboost, ad ogni iterazione, cambia il proprio comportamento adattandosi perfettamente al contesto specifico.

    \section{Dataset di Allenamento}
    \label{sec:training_dataset}
        Prima di procedere ulteriormente nella presentazione dell'algoritmo di allenamento, è necessario fare qualche considerazione preventiva sulla costruzione dei dataset di allenamento.

        Innanzi tutto, qualche delucidazione sui termini: è stato utilizzato largamente il termine \emph{insieme} per denotare l'organizzazione di dati in ingresso ad un algoritmo di allenamento, ma di qui in avanti si utilizzerà anche il termine \emph{dataset}.
        È un termine più legato al gergo tecnico, senza alcuna particolare accezione, se non quella di denotare un insieme organizzato in una reale struttura dati.

        \subsection{Categorie di Classificatori}
        \label{sub:classifiers_categories}
            È stato detto precedentemente che, come tutti gli algoritmi di supervised learning, Adaboost riceve in input un insieme di allenamento e restituisce un classificatore forte.

            Potrebbe non essere sufficiente disporre di un unico classificatore forte per l'applicazione di rilevamento che si vuole realizzare.

            \subsubsection{Variabilità della Forma delle Immagini HASP}
                La forma dell'immagine HASP della persona nel frame di profondità varia per molti motivi.

                La prima causa di variazione della forma HASP è l'\emph{orientazione della persona}.
                L'immagine di una persona che cammina seguendo una direzione parallela al lato lungo del frame sarà indubbiamente diversa dall'immagine di una persona che cammina seguendo una direzione perpendicolare, così come sarà diversa dall'immagine di una persona che compie una traiettoria obliqua all'interno della stanza.

                Un altro fattore importante che concorre nella variazione della forma è la \emph{distorsione prospettica}.
                L'immagine di una persona ripresa al centro del frame e quella della stessa persona ripresa in una zona periferica è molto diversa, anche se orientata sempre nella stessa direzione.

                L'entità della distorsione prospettica della forma è tanto maggiore quanto più il sensore è vicino al pavimento. 
                D'altro canto, le caratteristiche tecniche di quest'ultimo impongono un limite massimo alla distanza.
                
                Considerata la realtà applicativa del sistema, la distanza massima del sensore dal pavimento sarà di poco inferiore all'altezza del soffitto in una comune abitazione.
                L'altezza a cui viene montato il sensore, quindi, non verrà considerato un parametro progettuale, bensì una condizione ambientale entro la quale il sistema deve operare: la distorsione prospettica non può essere eliminata.

                Un'ulteriore causa della variazione della forma dell'immagine HASP consiste nelle \emph{differenze di corporatura e di statura delle persone}.
                Tali differenze vengono chiamate \emph{differenze interclasse}, essendo delle caratteristiche variabili di oggetti che appartengono alla stessa classe.
                Ovviemente un buon sistema di rilevamento dovrebbe essere in grado di riconoscere soggetti di differente statura e corporatura.
                Per ovviare a questo problema verranno prese delle opportune misure di ridimensionamento delle immagini.

            \subsubsection{Definizione delle Categorie di Classificatori}
                Una forte variabilità intraclasse potrebbe portare alla sintesi di classificatori troppo laschi.

                Un buon approccio a questo problema consiste nel dividere gli oggetti, appartenenti alla stessa classe, in diverse categorie.
                Tali categorie devono essere scelte in modo tale che le differenze tra gli oggetti appartenti alla stessa categoria siano lievi, mentre quelle relative agli oggetti di differenti categorie siano più accentuati.
                
                Definite tali categorie, per ognuna di esse verrà sintetizzato un classificatore, allendandolo solo su elementi appartenenti ad una stessa categoria.
                Così facendo le differenze intraclasse di entità superiore vengono arginate.

                L'\emph{orientazione della persona} è il parametro su cui si possono formulare le diverse categorie.
                In questo sistema vengono allenati due classificatori forti che vanno ad operare in parallelo (equazione \ref{eq:parallel_classifiers}) in fase di riconoscimento: il primo è allenato esclusivamente con immagini di persone che si muovono in direzione parallela al lato lungo del frame (informalmente, direzione \emph{orizzontale}), il secondo con immagini di persone che si muovono in direzione perpendicolare alla prima (direzione \emph{verticale}).

                \begin{equation}
                    \label{eq:parallel_classifiers}
                    F_{final}(x) = F_{hor}(x) || F_{ver}(x)
                \end{equation}

                Sarebbe possibile anche definire ulteriori categorie basate sulla direzione delle persona, introducendo due classificatori dedicati alle due \emph{direzioni oblique} rispetto alle prime due.

                Inoltre si può pensare di porre rimedio alla distorsione prospettica del sensore suddividendo il frame in aree ed allenando, per ognuna di esse, una coppia di classificatori orizzontale-verticale.

                Queste ultime due soluzioni introducono una certa complessità aggiuntiva ed in questa fase iniziale di sperimentazione non porteranno grandi vantaggi alla precisione complessiva del sistema.

        \subsection{Preparazione dei Dataset}
        \label{sub:datasets_setup}
            \subsubsection{Acquisizioni}
                Per la creazione dei dataset di allenamento è stato chiesto a 10 soggetti, di statura e corporatura differente, di percorrere una traiettoria differente per ogni registrazione.

                Delimitata fisicamente l'area del pavimento corrispondente all'area di visualizzazione del frame di profondità, sono state individuate tre traiettorie significative:

                \begin{description}
                    \item[Orizzontale] Seguendo questa traiettoria, i soggetti coprono tutta l'area muovendosi lungo le parallele al lato maggiore.

                    \item[Verticale] I soggetti coprono l'area muovendosi lungo la direzione perpendicolare al lato maggiore.

                    \item[Random] È stato chiesto ai soggetti di seguire una traiettoria casuale, cercando di coprire tutta l'area del frame.
                \end{description}

                I primi due percorsi corrispondo alle categorie individuate precedentemente: da tali registrazioni vengono estratti gli oggetti per l'allenamento dei classificatori che sono stati denominati, informalmente, orizzontale e verticale.

                Le registrazioni dell'ultima traiettoria, invece, vengono utilizzate per la creazione del \emph{dataset di validazione}\footnote{Per ulteriori informazioni, consultare il capitolo \ref{chap:tuning}, nella fattispecie la sottosezione \ref{sub:dataset_di_validazione}.}.

                Con un software di registrazione\footnote{Sviluppato al Laboratorio di Telecomunicazioni presso l'Università Politecnica delle Marche (\url{http://www.tlc.dii.univpm.it/blog/databases4kinect}).} apposito vengono sequenzialmente catturati e salvati i frame di profondità elaborati dal dispositivo Kinect, ad una frequenza massima di $30 fps$.
                Il software è in grado di catturare fino a 1000 frame, corrispondenti a poco più di mezzo minuto, che vengono salvati in file binari grezzi, senza ricorrere a compressione.

                La durata delle registrazioni delle traiettorie orizzontale e verticale è subordinata al tempo necessario al soggetto per coprire tutta l'area del frame, mentre le registrazioni riferite alle traiettorie casuali sono tutte costituite da 1000 frame.

            \subsubsection{Ritaglio dei Samples}
                È stato sviluppato un software apposito per la gestione dei dataset per ritagliare, organizzare e ridimensionare, le immagini dei dataset di allenamento.

                Attraverso un'efficace interfaccia utente, permette di aprire e visualizzare una registrazione e scorrere ciascun frame. 
                Una volta individuato il frame interessato, è possibile estrarre un ritaglio selezionando l'area. 
                La porzione selezionata di frame viene immediatamente salvata in un file binario grezzo nella cartella contenente il dataset correntemente aperto.

                Nell'appendice \ref{chap:training_set_creator} vi saranno ulteriori spiegazioni al riguardo.

        \subsection{Preprocessing}
        \label{sub:preprocessing}
            \subsubsection{Resize}
                In fase di creazione dei dataset è necessario effettuare una prima operazione di preprocessing.
                In virtù del fatto che, a soggetti di corporatura differente, corrispondo immagini HASP di dimensioni differenti, è necessario normalizzare le dimensioni dei ritagli componenti i dataset di allenamento.
                
                Tutte le immagini vengono quindi ridimensionate a $24 \times 24$ pixel, valore già utilizzato in letteratura nel framework proposto da Viola e Jones in \cite{Viola04}.
                Sono disponibili tre algoritmi per il resize delle immagini: \emph{nearest neighbour}, \emph{bilinear interpolation} e \emph{bicubic interpolation}.

                La scelta dell'algoritmo di resize è caduta sul \emph{nearest neighbour}, il più semplice ed il meno invasivo dei tre.

            \subsubsection{Conversione delle distanze}
                Un'ulteriore operazione di preprocessing da effettuare sugli elementi del dataset è la conversione delle distanze.
                
                Il valore di ciascun pixel nelle immagini di profondità, esprime la distanza in $mm$ della superficie rilevata dal sensore.
                È necessario elaborare le immagini di profondità trasformando la distanza della superficie dal sensore in \emph{quota della superficie dal pavimento}.
                \begin{equation}
                    \label{eq:floor_distance}
                    d' = d - d_{pavimento}
                \end{equation}

                L'equazione \ref{eq:floor_distance} esplicita la modalità di conversione delle distanze.
                Bisogna notare che il valore della distanza del pavimento dal sensore, non è uniforme in tutta l'area del frame, a causa della distorsione prospettica: nelle zone periferiche essa sarà maggiore.
                Si considera valida la distanza misurata esattamente al centro del frame, corrispondente a circa $2850mm$.

    \section{Procedura di Allenamento}
    \label{sec:training_procedure}
        \subsection{Notazione} % (fold)
        \label{sub:notazione}
            Sia $D$ un insieme di allenamento.
            \begin{equation}
                \label{subeq:training_set}
                D = \left\{(x_1, y_1), \cdots, (x_n, y_n)\right\}
            \end{equation}
            
            $D$ è costituito da $n$ coppie $(x_i, y_i)$, dove $x_i$ è un'immagine di profondità e $y_i$ è la relativa etichettatura reale.
     
            Il problema è di classificazione binaria, quindi ogni etichette $y_i$ rappresenta la \emph{classificazione} dell'oggetto $x_i$.
            Inoltre, poniamo che:

            \begin{equation}
                \label{eq:classification_notation}
                y_i =
                \begin{cases}
                    1 & \text{ se }x_i\text{ raffigura un umano }\\
                    0 & \text{ altrimenti }\\
                \end{cases}
            \end{equation}

            Se $y_i = 1$, si parlerà, in riferimento a $x_i$, di \emph{esempio positivo}, se $y_i = 0$ invece si parlerà di \emph{esempio negativo}.

            L'insieme $D$ può essere partizionato come segue:
            \begin{equation}
                \label{subeq:traininig_set_partitions}
                P = \left\{(x, y) \in D | y = 1\right\} 
                \text{ e } 
                N = \left\{(x,y) \in D | y = 0\right\}
            \end{equation}

            Si tenga presente che, essendo $P$ ed $N$ partizioni di $D$, valgono le seguenti\footnote{La scrittura $\#(D)$ denota la cardinalità dell'insieme $D$.}:
            \begin{equation}
                D = P \cup N
            \end{equation}
            \begin{equation}
                P \cap N = \emptyset
            \end{equation}
            \begin{equation}
                \#(D) = \#(P \cup N) = \#(P) + \#(N)
            \end{equation}
        % subsection notazione (end)

        \subsection{Definizione dei Weak Learner} % (fold)
        \label{sub:definizione_dei_weak_learner}
            È necessario, a questo punto, esplicitare ciò che andrà a costituire i weak learner.
            Viola e Jones in \cite{Viola04}, Zhu e Wong in \cite{Zhu13} utilizzano dei \emph{decision stump} equipaggiati per il calcolo delle feature di Haar sulle immagini di profondità.

            Come è stato detto nella sezione \ref{sec:decision_stump}, un decision stump è della forma espressa dall'equazione \ref{eq:decision_stump_test}.
            \begin{equation}
                \tag{\ref{eq:decision_stump_test}}
                h(x) = 
                \begin{cases}
                    1 & \text{ se } pf(x) < p\theta \\
                    0 & \text{ altrimenti }
                \end{cases}
            \end{equation}

            In questo specifico contesto, $f$ rappresenta una singola feature di Haar: esistono tanti weak learner tante sono le possibili feature di Haar per le immagini che costituiscono il dataset di allenamento.
            Il valore della soglia $\theta$ e quello della polarità $p \in \{-1,1\}$, sono i parametri liberi del weak learner, che verranno fissati in fase di allenamento.
            Verranno fornite ulteriori spiegazioni nelle sezioni successive (\ref{sub:strong_learner_extraction} e \ref{sec:weak_learner}).
        % subsection definizione_dei_weak_learner (end)

        \subsection{Procedura di Estrazione dello \emph{Strong Learner}} % (fold)
        \label{sub:strong_learner_extraction}
            La seguente procedura, descrive il processo di costruzione dello strong learner come combinazione di weak learner: è il corpo principale di Adaboost ed implementa le tecniche di boosting adattivo sul dataset di allenamento.
            Di seguito si presenta la sequenza di passi necessari alla combinazione di $T$ weak learner in un unico classificatore forte.

            \begin{enumerate}
                \item Si associa ad ogni elemento $(x_i, y_i) \in D$ un peso $w_i$ iniziale:
                \begin{equation}
                    \label{subeq:weighting_samples}
                    \forall (x_i, y_i) \in D \text{  }
                    w_i = 
                    \begin{cases}
                        \frac{1}{2l} & \text{ se } (x_i, y_i) \in P \text{ con } l = \#(P) \\
                        \frac{1}{2m} & \text{ se } (x_i, y_i) \in N \text{ con } m = \#(N) \\
                    \end{cases}
                \end{equation}

                Sia inoltre:
                \begin{equation}
                    \label{subeq:definition_of_n}
                    n := \#(D) = \left[\#(P) + \#(N) \right] = l + m
                \end{equation}

                \item \emph{For} $t = [1:T]$
                \begin{enumerate}
                    \item Si normalizzano i pesi, in modo che la loro somma sia pari ad 1:
                    \begin{equation}
                        \label{subeq:weight_nomalization}
                        w_{t,i} \leftarrow \frac{w_{t,i}}{\sum_{j = 1}^{n}w_{t,j}}
                    \end{equation}

                    \item \label{adaboost_minimum_error}
                    Si estrae il miglior weak learner. 
                    La procedura viene esposta nel dettaglio nella sezione \ref{sec:weak_learner}, ma si tenga presente che il miglior classificatore debole è quello il cui \emph{errore pesato} è minimo, in riferimento alla corrente iterazione.
                    \begin{equation}
                        \label{subeq:minimum_error}
                        \epsilon_t = \min_{f,p,\theta} \left\{
                        \sum_{i = 1}^{n} w_{t,i} \cdot |h(x_i, f, p, \theta) - y_i|
                        \right\} 
                    \end{equation}
                    
                    Siano inoltre $f_t$, $p_t$, $\theta_t$ i parametri del classificatore debole che ne minimizzano l'errore pesato:
                    \begin{equation}
                        \label{subeq:best_weak_classifier}
                        h_t(x) := h(x, f_t, p_t, \theta_t)
                    \end{equation}

                    \item \label{adaboost_beta} 
                    Si calcola il fattore moltiplicativo per la modifica dei pesi associati agli esempi di allenamento:
                    \begin{equation}
                        \label{subeq:weight_factor_definition}
                        \beta_t \leftarrow \frac{\epsilon_t}{1 - \epsilon_t}
                    \end{equation}

                    \item \label{adaboost_update_weights} Si aggiornano i pesi
                    \begin{equation}
                        \label{subeq:weight_update}
                        w_{t+1, i} \leftarrow w_{t,i} \cdot \beta_{t}^{e_i}
                    \end{equation}
                    dove:
                    \begin{equation}
                        \label{subeq:weak_learner_classification}
                        e_i = 
                        \begin{cases}
                            1 & \text{ se } (x_i, h_t(x_i)) \in D\\
                            0 & \text{ altrimenti }
                        \end{cases}
                    \end{equation}
                    È da notare che la prima condizione è vera solo nel caso in cui il weak learner $h_t$ ha predetto correttamente la classificazione di $x_i$.

                    \item Definizione del fattore moltiplicativo, ovvero il coefficiente nella combinazione lineare, per il weak learner corrente:
                    \begin{equation}
                        \label{subeq:alpha_factor}
                        \alpha_t \leftarrow \log\frac{1}{\beta_t}
                    \end{equation}
                \end{enumerate}

                \item \label{adaboost_strong_classifier} Il classificatore forte è dato da:
                \begin{equation}\label{eq:strong_classifier}
                    F(x) = 
                    \begin{cases}
                        1 & \text{ se } \sum_{t = 1}^{T} \alpha_t h_t(x) > \theta_{str} \sum_{t = 1}^{T} \alpha_t \\
                        0 & \text{ altrimenti }
                    \end{cases}
                \end{equation}
                dove $\theta_{str} \in [0,1]$ è la soglia dello strong learner.
            \end{enumerate}
            
            Si noti che, nel'operazione \ref{adaboost_minimum_error}, l'\emph{errore pesato} non è altro che la somma dei pesi degli esempi che non vengono classificati correttamente. 
            Infatti:
            \begin{equation}
                \label{subeq:minimum_error_evaluation}
                |h(x_i, f, p, \theta) - y_i| = 
                \begin{cases}
                    0 & \text{ se } h(x_i, f, p, \theta) = y_i \\
                    1 & \text{ se } h(x_i, f, p, \theta) \neq y_i
                \end{cases}
            \end{equation}

            Al punto \ref{adaboost_beta}, il valore di $\beta_t$ non è altro che il rapporto tra l'errore pesato del classificatore debole e la somma dei pesi delle immagini classificate correttamente. Tale valore è chiaramente $0 < \beta_t < 1$.

            In fase di aggiornamento dei pesi (punto \ref{adaboost_update_weights}), i pesi relativi ad esempi classificati correttamente vengono moltiplicati per $\beta_t$ ($\beta_{t}^{1} = \beta_t < 1$) e quindi decrementati, mentre gli altri vengono lasciati inalterati ($\beta_{t}^{0} = 1$). 
            Fare in modo che gli esempi non classificati correttamente abbiano un peso maggiore di quelli classificati correttamente è il modo per influenzare la scelta del classificatore debole successivo che andrà a colmare le lacune del suo predecessore.

            La scelta della soglia per il classificatore forte (punto \ref{adaboost_strong_classifier}) deve minimizzare il numero di esempi classificati in modo errato.
            La procedura di selezione viene spiegata nel dettaglio al capitolo \ref{chap:tuning}.
        % subsection strong_learner_extraction (end)
    
    \section{Selezione del \emph{Weak Learner} Migliore}
    \label{sec:weak_learner}
        La scelta del miglior weak learner mira ad identificare la feature di Haar, la polarità e la soglia che minimizzano l'errore pesato di classificazione.

        Si ricordi che le feature di Haar sono degli indicatori di quanto le intensità dei pixel variano da una regione della feature ad un'altra. 
        Il classificatore debole, quindi, prevederà l'etichettatura dell'immagine a seconda che tale indice sia maggiore o minore di una certa soglia. 
        Il compito della polarità è quello di stabilire il verso della diseguaglianza.

        \subsection{Pool delle Feature di Haar} % (fold)
        \label{sub:features_pool}
            Il pool delle feature di Haar da testare è costituito da tutte le possibili configurazioni valutabili sulle immagini di allenamento.
            Viola e Jones utilizzano immagini di allenamento di $24 \times 24$ pixel e 5 tipologie di feature differenti (\cite[sezione 2.2]{Viola04}).

            Contrariamente a quanto potrebbe sembrare, già in dimensioni così limitate il numero di configurazioni possibili raggiunge l'ordine delle centinaia di migliaia\footnote{Questo è un ulteriore motivo per voler ridimensionare la dimensione degli esempi di allenamento: la figura umana in una immagine di profondità catturata con il KinectV2 ha dimensioni comprese tra i $120 \times 120$ pixel ed i $160 \times 160$ pixel. È impossibile valutare tutte le possibili feature in un'area così grande in tempi accettabili.}.

            In questa applicazione, come è stato già detto, si utilizzano immagini di allenamento delle stesse dimensioni, adeguatamente ricampionate dopo il ritaglio.
            Inoltre, si utilizzano solamente quattro feature di Haar, due composte da due rettangoli di egual misura e due composte da tre rettangoli uguali affiancati (confrontare la sottosezione \ref{sub:haar_features_applications} ed in particolare la figura \ref{fig:features_type}): ciò genera un pool di feature possibili di poco più di un centinaio di migliaia di configurazioni differenti, per cui i tempi di calcolo complessivi risulteranno ancora ragionevoli.
        % subsection features_pool (end)

        \subsection{Procedura di Selezione} % (fold)
        \label{sub:weak_learner_selection_procedure}
            La procedura di selezione del miglior weak learner viene richiamata al punto \ref{adaboost_minimum_error} della procedura di allenamento principale.

            Sia $\left\{f_1,\cdots,f_k\right\}$ l'insieme di tutte le feature selezionabili, $D = \left\{(x_1,y_1), \cdots, (x_n, y_n) \right\}$ l'insieme degli esempi di allenamento e $\left\{w_1, \cdots, w_n\right\}$ l'insieme dei relativi pesi\footnote{Essendo richiamata all'interno del loop principale di Adaboost, saranno disponibili i pesi relativi agli esempi di allenamento in riferimento all'iterazione corrente.}. 
            La scelta del classificatore debole avviene come descritto dal seguente algoritmo.

            \begin{enumerate}
                \item Si calcolano $T^+$ e $T^-$, rispettivamente, somma dei pesi degli esempi negativi e di quelli negativi:
                \begin{equation}
                    \label{subeq:weight_total_sums}
                    T^+ \leftarrow \sum_{i = 1}^{n} (w_i y_i)
                    \text{ , }
                    T^- \leftarrow \sum_{i = 1}^{n} \left[w_i (1 - y_i)\right]
                \end{equation}

                \item \emph{For each} $f \in \left\{f_1, \cdots, f_k\right\}$

                \begin{enumerate}
                    \item Si inizializza una lista di $n$ elementi per memorizzare i valori della feature $i$-esima applicata ad ogni immagine di allenamento:
                    \begin{equation}
                        \label{subeq:element_list_initialization}
                        values[i] \leftarrow f(x_i) \; \forall x_i \in D
                    \end{equation}

                    \item Si ordinano gli elementi della lista in \emph{ordine crescente}. 
                    Si tenga in conto che, dopo tale operazione, all'$i$-esima posizione della lista non corrisponderà più il valore della feature applicata all'\emph{i}-esima immagine di allenamento.

                    \item Si inizializzano $S^+$ ed $S^-$, con le quali, \emph{scorrendo gli elementi della lista con un cursore, si indicheranno rispettivamente la somma dei pesi degli esempi positivi e di quelli negativi}:
                    \begin{equation}
                        \label{subeq:partial_sum_initialization}
                        S^+ \leftarrow 0, S^- \leftarrow 0
                    \end{equation}

                    \item \emph{For} $i = [1:n]$

                    \begin{enumerate}
                        \item A causa del rilocamento degli indici, alla posizione $i$-esima della lista corrisponderà il valore della feature dell'elemento $x_j$ con classificazione $y_j$ e peso $w_j$ tale che $(x_j, y_j) \in D$:
                        \begin{equation}
                            \label{subeq:indices_relocation}
                            x_j, y_j, w_j \Leftarrow values[i]
                        \end{equation}

                        \item \emph{If} $y_i = 1$ \emph{Then}
                        \begin{enumerate}
                            \item $S^+ \leftarrow S^+ + w_j$
                        \end{enumerate}
                        \item \emph{Else}
                        \begin{enumerate}
                            \item $S^- \leftarrow S^- + w_j$
                        \end{enumerate}

                        \item \label{best_classifier_p_theta}
                        Si calcola l'errore pesato di classificazione (questo passaggio è critico, seguiranno ulteriori commenti e spiegazioni):
                        \begin{equation}
                            \label{subeq:weighted_error_calculus}
                            e_i = \min\left\{ \left[S^+ + (T^- - S^-)\right], \left[S^- + (T^+ - S^+)\right] \right\}
                        \end{equation}
                        Inoltre, si determinano la polarità ed il valore di soglia:
                        \begin{equation}
                            \label{subeq:polarity_assignment}
                            p_i = 
                            \begin{cases}
                                1 & \text{ se } S^+ + (T^- - S^-) > S^- + (T^+ - S^+) \\
                                -1 & \text{ altrimenti }
                            \end{cases}
                        \end{equation}
                        \begin{equation}
                            \label{subeq:threshold_assignment}
                            \theta_i = values[i]
                        \end{equation}

                    \end{enumerate}

                    \item Si determinano la polarità ($p_f$) e la soglia ($\theta_f$) per cui l'errore pesato ($\epsilon_f)$ di classificazione per un classificatore che utilizza la feature $f$ è minimo:
                    \begin{equation}
                        \label{subeq:minimum_error_polarity_and_threshold}
                        (p_f, \theta_f) \leftarrow (p_i, \theta_i) 
                        \text{ } | \text{ } 
                        \begin{cases}
                            \epsilon_f = \underset{i \in \{1, \cdots, n\}}\min{\left\{ e_1, \cdots, e_n \right\}} & \\
                            i = \argmin{i \in \{1, \cdots, n\}}{\left\{ e_1, \cdots, e_n \right\}}
                        \end{cases}
                    \end{equation}

                    \item Si costruisce il weak learner basato sulla feature $f$ più adeguato per la classificazione, fissando i suoi parametri liberi:
                    \begin{equation}
                        \label{subeq:weak_learner_specifications}
                        h_f(x) \leftarrow h(x, f, p, \theta)|_{p = p_f, \theta = \theta_f}
                    \end{equation}
                \end{enumerate}

                \item Ottenuti i weak learner $\left\{h_1(x), \cdots, h_k(x)\right\}$ (uno per ogni feature), correlati dei rispettivi errori pesati nella classificazione del dataset di allenamento $E = \left \{ \epsilon_1, \cdots, \epsilon_k \right \}$, si sceglie quello con l'errore pesato più basso, relativamente all'iterazione $t$-esima del ciclo principale di Adaboost.
                \begin{equation}
                    \label{subeq:best_weak_learner}
                    h_t(x) \leftarrow h_j(x) = h(x, f_j, p_{f_j}, \theta_{f_j})| j = \argmin{j \in \{1, \cdots, k\}}{\{\epsilon_1, \cdots, \epsilon_k\}}
                \end{equation}

            \end{enumerate}

            La selezione della polarità e della soglia ottimi per il weak learner costruito sulla generica feature $f$ (punto \ref{best_classifier_p_theta}) è un passaggio particolarmente critico e necessita di ulteriori spiegazioni.
            Selezionare un valore di soglia vuol dire trovare il \emph{punto che partiziona al meglio la lista dei valori della feature calcolata sulle immagini di allenamento, al fine di minimizzare gli errori di classificazione}.
            
            Si tenga bene a mente che la lista dei valori delle feature viene, innanzi tutto, ordinata in ordine crescente.
            La miglior soglia di una buona feature fa in modo che la maggior parte delle immagini appartenenti alla stessa classe assumano un valore minore (o maggiore) della soglia stessa.

            Scorrendo una sola volta la lista dei valori ($values[1...n]$) della feature associati ad ogni immagine, si è in grado di trovare il valore di soglia.
            Bisogna effettuare alcune considerazioni sul significato delle somme presentate al punto \ref{best_classifier_p_theta}:
            \begin{enumerate}
                \item \label{obs:1} $T^+$, ($T^-$) corrisponde alla somma dei pesi degli esempi positivi (negativi)
                \item \label{obs:2} $S^+$, ($S^-$) corrisponde alla somma dei pesi degli esempi positivi (negativi) dalla prima posizione fino all'i-esima della lista (quella in cui è posizionato il cursore)
                \item \label{obs:3} $T^+ - S^+$, ($T^- - S^-$) corrisponde alla somma dei pesi degli esempi positivi (negativi) dalla posizione $i+1$ della lista fino alla fine
                \item \label{obs:4} Per un classificatore della forma \ref{eq:decision_stump_test} con $p = 1$, $S^+$ corrisponde alla \emph{somma dei pesi degli esempi classificati correttamente}, mentre $S^- + (T^+ - S^+)$ corrisponde alla somma dei pesi degli esempi classificati in modo scorretto
                \item \label{obs:5} Per l'osservazione \ref{obs:4} un classificatore con $p = 1$, la quantità $S^- + (T^+ - S^+)$ è \emph{l'errore pesato}
                \item \label{obs:6} Analogamente alle osservazioni \ref{obs:4} e \ref{obs:5}, un classificatore con $p = -1$ commetterà un errore pesato pari alla quantità $S^+ + (T^- - S^-)$
            \end{enumerate}

            Scorrendo la lista, si sceglierà come soglia, il valore che minimizza l'errore pesato di classificazione.
            Il calcolo dell'errore pesato è specificato dall'equazione \ref{subeq:weighted_error_calculus} e deriva dalle osservazioni \ref{obs:5} e \ref{obs:6}.
            Inoltre, per grazie alle stesse osservazioni, si ottiene anche la corretta polarità (equazione \ref{subeq:polarity_assignment}).
        % subsection procedura_di_selezione (end)           

        \subsection{Valutazione della complessità computazionale}
            In definitiva, con uno scorrimento della lista ordinata si ottengono i parametri per la costruzione del classificatore debole. 
            La complessità di tale operazione è fortemente legata all'algoritmo di ordinamento della lista, la quale ha $\Theta(n\log n)$ come limite teorico inferiore \cite[p. 167]{Cormen09}.
            Nell'implementazione è stato scelto proprio un algoritmo che avesse complessità $O(n\log n)$ nel caso peggiore. 

            Ripetendo queste operazioni per ognuna delle feature selezionabili, si ottiene che l'algoritmo di selezione del miglior classificatore debole ha complessità $O(kn \log n)$.

            Complessivamente, l'intera procedura di allenamento ha complessità computazionale, nel caso peggiore, pari a $O(tkn \log n)$.
