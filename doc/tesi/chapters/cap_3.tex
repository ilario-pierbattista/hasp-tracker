% !TEX root=../index.tex

\chapter{L'Algoritmo di Allenamento: Adaboost}
\label{chap:adaboost}
    \section{\emph{Ensamble Supervised Learning}}
    \label{sec:supervised_ensamble_learning}
        L'algoritmo di \emph{machine learning} utilizzato dal Zhu e Wong in \cite{Zhu13} è chiamato \emph{Adaboost}, appartenente alla famiglia degli algoritmi di allenamento supervisionati, in particolare a quella degli \emph{ensamble learner}.

        \subsection{Apprendimento Supervisionato}
        \label{sub:supervised_learning}
            \subsubsection{Definizione}
                Gli algoritmi di apprendimento supervisionato funzionano attraverso l'utilizzo di un insieme di allenamento, ovvero un insieme i cui elementi sono formati da coppie di oggetti e le relative etichette.

                \begin{equation}
                    \label{subeq:training_set_labelled}
                    T = \left\{(x_1, y_1), \cdots, (x_n, y_n)\right\} 
                    \text{ con } 
                    y_1, \cdots, y_n \in L = \left\{l_1, \cdots, l_k, \cdots \right\}
                \end{equation}

                Esiste una funzione $f$ che associa ad ogni elemento $x$ l'etichetta $y$ corretta, ovvero in modo tale che:

                \begin{equation}
                    \label{subeq:unknown_function}
                    f:Dom(f) \rightarrow L | \forall x \in Dom(f), (x, f(x)) \in T
                \end{equation}

                Se l'insieme $L$ delle etichette è costituito da un numero finito di elementi ($L = \{l_1, \cdots, l_k\}$), allora il problema dell'associazione oggetto-etichetta, prende il nome di problema di \emph{classificatore} e la funzione $f$ sarà il relativo classificatore reale.
                
                L'obiettivo dell'apprendimento supervisionato è quello di trovare la \emph{migliore} funzione $h$ che approssima il classificatore reale, essendo sconosciuto.

                L'algoritmo di apprendimento cerca la funzione $h$, chiamata \emph{ipotesi}, all'interno dello \emph{spazio delle ipotesi} $\mathcal{H}$, scegliendo quella in grado di fornire le prestazioni migliori, sia rispetto agli elementi dell'insieme di allenamento, che rispetto ad altri elementi aggiuntivi\footnote{Si costruisce anche un insieme di testing per la valutazione delle prestazioni. Per non appesantire eccessivamente la lettura, i dettagli riguardo al testing vengono omessi ad un livello di trattazione così generale. Si faccia riferimento alla sottosezione \ref{sub:dataset_di_validazione} per ulteriori chiarimenti.}.
                Si considera una ipotesi $h$ una buona \emph{generalizzazione} di $f$, quando riesce ad etichettare correttamente anche nuovi oggetti.

                Molto spesso la funzione di classificazione reale $f$ non dipende strettamente dall'oggetto $x$, ma è costituita da un \emph{processo stocastico}: in tal caso, ciò che l'algoritmo deve apprendere è una \emph{distribuzione di probabilità condizionale} $P(Y|x)$.

                \begin{equation}
                    \label{subeq:stochastic_hypotesis_choice}
                    h^* = \argmax{h \in \mathcal{H}}{P(h | data)}
                \end{equation}

                La scelta del corretto spazio delle ipotesi è fondamentale.
                È necessario trovare un compromesso tra l'\emph{espressività delle ipotesi} nello spazio $\mathcal{H}$ e la \emph{complessità computazionale della scelta di una buona ipotesi}.
                Complessivamente, il tempo di calcolo dell'allenamento, tende ad aumentare molto velocemente all'aumento della \emph{dimensione} dello spazio $\mathcal{H}$ e della \emph{complessità computazionale} nel calcolo da ogni singola ipotesi.  

            \subsubsection{Esempi di \emph{Supervised Learning}}
                Esistono molti algoritmi di apprendimento supervisionato.
                Alcuni dei più famosi sono l'\emph{apprendimento di alberi decisionali}, l'\emph{addestramento su reti neurali} e le \emph{macchine a vettori di supporto}.

                Nell'apprendimento di alberi decisionali, definito un insieme di allenamento (\ref{subeq:training_set_labelled}) ed una collezione di \emph{attributi} valutabili sugli oggetti di tale insieme, si costruisce l'albero ramo per ramo, associando alla valutazione di ogni attributo il risultato più probabile.
                Più nel dettaglio, se l'insieme degli esempi di allenamento non è vuoto, se la classificazione su tali esempi non è sempre la stessa e se l'insieme degli attributi valutabili non è vuoto, allora si seleziona l'attributo più \emph{importante}\footnote{Minore è l'\emph{entropia} correlata all'attributo, maggiore è la sua \emph{importanza}. Nella teoria dell'informazione, ci si riferisce al concetto di \emph{entropia di Shannon}, ovvero alla misura dell'incertezza su una variabile aleatoria.
                Per una variabile aleatoria $V$ con $v_1,\cdots, v_k$ possibili valori, ognuno con probabilità $P(v_i)$, l'entropia relativa a $V$ sarà $H(V) = \sum_{i = 1}^{k}P(v_i)\log_2\frac{1}{P(v_i)} = - \sum_{i = 1}^{k}P(v_i)\log_2P(v_i)$}.
                Si valuta l'attributo su tutti gli esempi di allenamento e, per ogni valore che esso assume, si partiziona l'insieme di allenamento stesso in base a tale valore.
                Per ogni partizione, si allena un sottoalbero utilizzando la stessa procedura, prendendo in considerazione però, la collezione degli attributi privata dell'attributo appena valutato.

                Una rete neurale è una particolare struttura decisionale che ricorda la struttura neurale del cervello umano.
                Come una qualsiasi rete è rappresentabile con un grafo, in cui i nodi sono detti \emph{units} e gli archi \emph{links}.
                Un generico link dall'unità $i$ all'unità $j$ propaga l'attivazione $a_i$ dai due nodi. Ad ognuno di essi è inoltre associato un \emph{peso} $w_{ij}$, che denota la forza ed il segno della connessione.
                L'unità $j$-esima, calcola innanzitutto la combinazione lineare dei segnali in input e dei rispettivi pesi, quindi, in prossimità del valore ottenuto, calcola il risultato della \emph{funzione di attivazione} (\ref{subeq:activation_function}).
                \begin{equation}
                    \label{subeq:activation_function}
                    a_j = g(in_j) = g\left(\sum_{i = 0}^{n}w_{ij}a_i\right)
                \end{equation}
                La definizione delle funzioni di attivazione è un parametro progettuale relativo alla rete da compiere a priori dell'allenamento: a seconda del particolare obiettivo che si vuole perseguire, si sceglie una struttura neurale piuttosto che un'altra.
                In fase di allenamento, invece, si procede determinare il valore ottimo di ciascun peso relativo agli archi della rete: dato un insieme di allenamento, si cerca di mappare nel modo migliore possibile ciascun input al relativo valore di output.

                Le \emph{Support Vector Machine} (SVM) sono, attualmente, il framework di allenamento supervisionato più popolare.
                Godono di tre caratteristiche:
                \begin{enumerate}
                    \item Costruiscono un \emph{margine di separazione massimale} tra gli elementi del dataset di allenamento. Si tratta di un confine che separa gli esempi di allenamento distanziando più possibile gli elementi di classi diverse. Questa caratteristica garantisce un buon grado di generalizzazione.

                    \item Creano degli \emph{iperpiani lineari di separazione}. Elementi che non possono essere separati linearmente nello spazio originale di separazione, vengono rappresentati in spazi con un numero più elevato di dimensioni, al fine di trovare un iperpiano lineare come separatore.

                    \item Combinano i vantaggi dei metodi \emph{parametrici} e \emph{non parametrici}\footnote{I modelli \emph{parametrici} caratterizzano gli elementi di un insieme di allenamento utilizzando un numero prefissato di parametri, indipendentemente dalla cardinalità dell'insieme. 
                    Ad esempio, nelle reti neurali, il numero di pesi da fissare è una caratteristica strutturale della rete.
                    Di contro, i metodi \emph{non parametrici} non sono caratterizzati da un limite prefissato di parametri con cui caratterizzare gli esempi di allenamento.} risultando molto flessibili nella rappresentazione di funzioni di classificazione complesse, ma poco sensibili a problematiche di \emph{overfitting}.
                \end{enumerate}

            \subsubsection{\emph{Overfitting}}
                Le tecniche di addestramento supervisionato potrebbero incorrere in problemi di \emph{overfitting}.
                Dato un insieme di allenamento, infatti, la ricerca delle ipotesi che approssimano al meglio la funzione obiettivo potrebbe essere influenzata da caratteristiche che sono comuni tra gli elementi dell'insieme stesso, ma che non sono discriminanti nella descrizione più generale della classe di oggetti.

                La variabilità \emph{intraclasse} delle caratteristiche degli esempi di allenamento, viene equivocata, in fase di eselezione, per variabilità \emph{extraclasse} e utilizzata, erroneamente, per la classificazione.

                Ciò porta ad un sequenziale miglioramento delle prestazioni del riconoscimento per gli elementi del dataset di allenamento, ma a prestazioni peggiori nella classificazione di nuovi elementi.

                Nella sottosezione \ref{sub:dataset_di_validazione}, verranno esposte alcune tecniche per evitare l'insorgere di problemi di overfitting.

            \subsubsection{\emph{Ensamble Learning}}
                Gli algoritmi di \emph{ensamble learning} sono una particolare categoria di algoritmi di apprendimento supervisionato.

                L'approssimazione della funzione obiettivo avviene mediante la selezione di una collezione di funzioni dallo spazio delle ipotesi.
                La predizione della classificazione dell'oggetto avviene, poi, combinando tra loro il risultato delle predizioni formulate dalle singole ipotesi.
                
                Un classificatore allenato con un algoritmo di ensamble learning, intuitivamente, fornisce previsioni più accurate, ampliando il numero di ipotesi vincenti scelte per le predizioni.

        \subsection{\emph{Adaptive Boosting}}
        \label{sub:adaptive_boosting}
            \subsubsection{\emph{Strong} e \emph{Weak Learner}}
                Di qui in avanti, si farà riferimento due tipologie distinte di classificatori, i \emph{weak learner} e gli \emph{strong learner}\footnote{Alternativamente, \emph{weak classifier} e \emph{strong classifier}.}.

                I \emph{weak learner} sono costituiti da singole ipotesi, selezionate da utilizzando un qualsiasi algoritmo di allenamento supervisionato.
                La loro caratteristica principale è quella di essere meccanismi di classificazione estremamente semplici, anche dal punto di vista computazionale, e nel complesso, la loro attendibilità viene considerata di poco maggiore rispetto ad una previsione casuale.

                Gli \emph{strong learner}, invece, sono delle combinazioni di weak learner.
                Vengono definiti grazie all'implementazione di un metodo di ensamble boosting e garantiscono un'affidabilità molto maggiore rispetto ad i singoli weak learner.

            \subsubsection{Algoritmi di Boosting}
            \label{subsub:boostin_alg}
                Sono la famiglia più popolare di algoritmi che implementano l'ensamble learning.

                Inizialmente, gli algoritmi di questo tipo, associano ad un insieme di allenamento una distribuzione: ogni elemento viene correlato di un peso.
                Iterativamente viene selezionato, dallo spazio delle ipotesi, il \emph{miglior weak learner}, ovvero quello che riesce a classificare gli elementi del dataset compiendo meno errori possibili.

                L'idea che è alla base del successo degli algoritmi di boosting sta nel fatto che, tali pesi, vengono aggiornati per ogni elemento ad ogni iterazione in base al risultato della classificazione con il weak learner corrente. 
                Viene diminuito il peso degli elementi classificati correttamente e aumentato quello degli altri, in modo da favorire la selezione, all'iterazione successiva, di un weak learner che vada a compensare gli errori compiuti dal precedente.

                Tutti i weak learner selezionati combinano le loro singole predizioni in un'unica predizione molto accurata: lo strong learner risultante sarà la combinazione dei weak learner estratti.

            \subsubsection{Adaboost}
                Adaboost è l'algoritmo proposto da Freund e Schapire in \cite{Freund97}, ed è valso loro il premio Gödel per il contributo originale apportato al campo dell'informatica teorica.

                Il nome \emph{Adaboost} deriva dalla fusione delle parole \emph{Adaptive} e \emph{Boosting} (ed essendo un algoritmo di boosting, implementa le operazioni descritte precedentemente).

                Ciò che rende Adaboost un algoritmo di boosting \emph{adaptive} è la politica di aggiornamento dei pesi relativi agli elementi dell'insieme di allenamento: viene decrementato il peso degli elementi classificati correttamente, lasciando invariato il peso degli altri.

                Il valore di tale decremento non è costante, ma \emph{dipende dall'errore pesato di classificazione complessivo} per la relativa iterazione. 
                Maggiore è l'errore, maggiore è il decremento dei pesi.
                
                È così che Adaboost, ad ogni iterazione, cambia il proprio comportamento adattandosi perfettamente al contesto specifico.

    \section{Dataset di Allenamento}
    \label{sec:training_dataset}
        Prima di procedere ulteriormente nella presentazione dell'algoritmo di allenamento, è necessario fare qualche considerazione preventiva sulla costruzione dei dataset di allenamento.

        Innanzi tutto, qualche delucidazione sui termini: è stato utilizzato largamente il termine \emph{insieme} per denotare l'organizzazione di dati in ingresso ad un algoritmo di allenamento, ma di qui in avanti si utilizzerà anche il termine \emph{dataset}.
        È un termine più legato al gergo tecnico, senza alcuna particolare accezione, se non quella di denotare un insieme organizzato in una reale struttura dati.

        \subsection{Categorie di Classificatori}
        \label{sub:classifiers_categories}
            È stato detto precedentemente che, come tutti gli algoritmi di supervised learning, Adaboost riceve in input un insieme di allenamento e resitituisce un classificatore forte.

            Potrebbe non essere sufficiente disporre di un unico classificatore forte per l'applicazione di rilevamento che si vuole realizzare.

            \subsubsection{Variabilità della Forma delle Immagini HASP}
                La forma dell'immagine HASP della persona nel frame di profondità varia per molti motivi.

                La prima causa di variazione della forma HASP è l'\emph{orientazione delle persona}.
                L'immagine di una persona che cammina seguendo una direzione parallela al lato lungo del frame sarà indubbiamente diversa dall'immagine di una persona che cammina seguendo una direzione perpendicolare, così come sarà diversa dall'immagine di una persona che compie una traiettoria obliqua all'interno della stanza.

                Un altro fattore importante che concorre nella variazione della forma è la \emph{distorsione prospettica}.
                L'immagine di una persona ripresa al centro del frame e quella della stessa persona ripresa in una zona periferica è molto diversa, anche se orientata sempre nella stessa direzione.

                L'entità della distorsione prospettica della forma è tanto maggiore quanto più il sensore è vicino al pavimento. 
                D'altro canto, le caratteristiche tecniche di quest'ultimo impongono un limite massimo alla distanza.
                
                Considerata la realtà applicativa del sistema, la distanza massima del sensore dal pavimento sarà di poco inferiore all'altezza del soffitto in una comune abitazione.
                L'altezza a cui viene montato il sensore, quindi, non verrà considerato un parametro progettuale, bensì una condizione ambientale entro la quale il sistema deve operare: la distorsione prospettica non può essere eliminata.

                Un'ulteriore causa della variazione della forma dell'immagine HASP consiste nelle \emph{differenze di corporatura e di statura delle persone}.
                Tali differenze vengono chiamate \emph{differenze interclasse}, essendo delle caratteristiche variabili di oggetti che appartengono alla stessa classe.
                Ovviemente un buon sistema di rilevamento dovrebbe essere in grado di riconoscere soggetti di differente statura e corporatura.
                Per ovviare a questo problema verranno prese delle opportune misure di ridimensionamento delle immagini.

            \subsubsection{Definizione delle Categorie di Classificatori}
                Una forte variabilità intraclasse potrebbe portare alla sintesi di classificatori troppo laschi.

                Un buon approccio a questo problema consiste nel dividere gli oggetti, appartenenti alla stessa classe, in diverse categorie.
                Tali categorie devono essere scelte in modo tale che le differenze tra gli oggetti appartenti alla stessa categoria siano lievi, mentre quelle relative agli oggetti di differenti categorie siano più accentuati.
                
                Definite tali categorie, per ognuna di esse verrà sintetizzato un classificatore, allendandolo solo su elementi appartenenti ad una stessa categoria.
                Così facendo le differenze intraclasse di entità superiore vengono arginate.

                L'\emph{orientazione della persona} è il parametro su cui si possono formulare le diverse categorie.
                In questo sistema vengono allenati due classificatori forti che vanno ad operare in parallelo (equazione \ref{eq:parallel_classifiers}) in fase di riconoscimento: il primo è allenato esclusivamente con immagini di persone che si muovono in direzione parallela al lato lungo del frame (informalmente, direzione \emph{orizzontale}), il secondo con immagini di persone che si muovono in direzione perpendicolare alla prima (direzione \emph{verticale}).

                \begin{equation}
                    \label{eq:parallel_classifiers}
                    F_{final}(x) = F_{hor}(x) || F_{ver}(x)
                \end{equation}

                Sarebbe possibile anche definire ulteriori categorie basate sulla direzione delle persona, introducendo due classificatori dedicati alle due \emph{direzioni oblique} rispetto alle prime due.

                Inoltre si può pensare di porre rimedio alla distorsione prospettica del sensore suddividendo il frame in aree ed allenando, per ognuna di esse, una coppia di classificatori orizzontale-verticale.
                
                Queste ultime due soluzioni introducono una certa complessità aggiuntiva ed in questa fase iniziale di sperimentazione non porteranno grandi vantaggi alla precisione complessiva del sistema.

        \subsection{Preparazione dei Dataset}
        \label{sub:datasets_setup}
            \subsubsection{Acquisizioni}
                % \paragraph{Soggetti, percorsi}
                Per la creazione dei dataset di allenamento è stato chiesto a 10 soggetti, di statura e corporatura differente, di percorrere una traiettoria differente per ogni registrazione.
                Delimitata l'area del pavimento corrispondente all'area di visualizzazione del frame di profondità, sono state individuate 3 traiettorie:
                \begin{description}
                    \item[Orizzontale] È stato chiesto ai soggetti di coprire tutta l'area muovendosi lungo la direzione parallela al lato maggiore;
                    \item[Verticale] È stato chiesto ai soggetti di comprire tutta l'area muovendosi lungo la direzione perpendicolare al lato maggiore;
                    \item[Random] È stato chiesto ai soggetti di seguire una traiettoria casuale, cercando di coprire tutta l'area del frame.
                \end{description}
                Le prime due traiettorie corrispondo alle categorie individuate precedentemente: da tali registrazioni vengono estratti gli oggetti per l'allenamento dei classificatori orizzontale e verticale.
                Le registrazioni dell'ultima traiettoria, invece, vengono utilizzate per la creazione del dataset di validazione.

                % \paragraph{Acquisizione delle registrazioni}
                Con un software apposito %@TODO Inserire crediti
                vengono sequenzialmente catturati e salvati i frame di profondità provenienti dal dispositivo Kinect, ad una frequenza massima di $30 fps$.
                Il software è in grado di catturare fino a 1000 frame, che vengono salvati in file binari grezzi, senza ricorrere a compressione.
                La durata delle registrazioni delle traiettorie orizzontale e verticale è subordinata al tempo necessario al soggetto per coprire tutta l'area del frame, mentre le registrazioni riferite alle traiettorie casuali sono tutte costituite da 1000 frame.

            \subsubsection{Ritaglio dei samples}
                % \paragraph{Trainset Creator}
                È stato sviluppato \emph{ad hoc} un applicativo dedicato alla creazione e alla gestione dei dataset di allenamento.
                Attraverso un'efficace interfaccia utente, permette di aprire e visualizzare una registrazione e scorrere ciascun frame. Una volta individuato il frame interessato, è possibile estrarre un ritaglio selezionando l'area. La porzione selezionata di frame viene immediatamente salvata in un file binario grezzo nella cartella contenente il dataset correntemente aperto.
                [Appendici per spiegazioni migliori]

        \subsection{Preprocessing}
        \label{sub:preprocessing}
            \subsubsection{Resize}
                In fase di creazione dei dataset è necessario effettuare una prima operazione di preprocessing.
                In virtù del fatto che, a soggetti di corporatura differente, corrispondo immagini HASP di dimensioni differenti, è necessario normalizzare le dimensioni dei ritagli componenti i dataset di allenamento.
                Tutte le immagini vengono quindi ridimensionate a $24 \times 24$ pixel (valore noto in letteretura).

                % \paragraph{Possibili algoritmi di resize}
                I possibili algoritmi per il ridimensionamento delle immagini sono \emph{nearest neighbour}, \emph{bilinear interpolation} ed \emph{bicubic interpolation}.
                Il ridimensionamento degli elementi del dataset si può effettuare direttamente dal software di gestione, che implementa i tre algoritmi precedenti.

                % \paragraph{Nearest Neighbour}
                L'algoritmo nearest neighbour è quello maggiormente utilizzato in quanto è il meno invasivo dei tre.

            \subsubsection{Conversione delle distanze}
                Un'ulteriore operazione di preprocessing da effettuare sugli elementi del dataset è la conversione delle distanze.
                Convertire le distanze dal sensore in quote dal pavimento.

    \section{\emph{Strong Learner} [Da revisionare]}
    \label{sec:strong_learner}
        \subsection{Procedura di Estrazione del Classificatore forte}
            Sia $D = \{(x_1, y_1), ..., (x_n, y_n)\}$ un insieme di $n$ coppie costituite da un'immagine ($x_i$) e la relativa classificazione reale ($y_i \in \{ 0, 1 \}$). Se $y_i = 1$, allora $x_i$ appartiene alla classe \emph{umano} (la coppia $(x_i, y_i)$ prende il nome di \emph{esempio positivo}), altrimenti appartiene alla classe \emph{non umano} (la coppia $(x_i, y_i)$ prende il nome di \emph{esempio negativo}).

            L'insieme $D$ può essere partizionato come segue:
            $$P = \{(x, y) \in D | y = 1\} \text{ e } N = \{(x,y) \in D | y = 0\}$$

            Si tenga presente che, essendo $P$ ed $N$ partizioni di $D$, valgono le seguenti\footnote{La scrittura $\#(D)$ denota il numero di elementi dell'insieme $D$.}:
            \begin{equation}
                D = P \cup N
            \end{equation}
            \begin{equation}
                P \cap N = \emptyset
            \end{equation}
            \begin{equation}
                \#(D) = \#(P \cup N) = \#(P) + \#(N)
            \end{equation}

            Si introduce anche il concetto di \emph{classificatore debole}. Si tratta di una funzione che per una data immagine $x$ in ingresso, assume il valore che simboleggia la presunta classe di appartenenza di quest'ultima.
            Nel dettaglio:
            \begin{equation}
                h(x) = \begin{cases}
                1 & \text{se $pf(x) < p\theta$}\\
                0 & \text{altrimenti}
            \end{cases}
            \end{equation}
            dove $f(x)$ è il valore di una feature di Haar applicata all'immagine $x$, $p \in \{-1,1\}$ è detta \emph{polarità} e $\theta$ è la \emph{soglia} (\emph{threshold}). Tutti i classificatori deboli sono costruiti usando un'unica feature.

            L'obbiettivo di Adaboost è quello di formare un \emph{classificatore forte} come combinazione lineare dei migliori classificatori deboli estraibili dal set di allenamento, dove il fattore moltiplicativo di ogni classificatore nella combinazione è inversamente proporzionale agli errori di classificazione compiuti da quest'ultimo in fase di allenamento.

            Il seguente algoritmo descrive la procedura di estrazione e combinazone di $T$ classificatori deboli.

            \begin{enumerate}
                \item Si associa ad ogni elemento $(x_i, y_i) \in D$ un peso $w_i$ tale che $w_i = \frac{1}{2l}$ se $(x_i, y_i) \in P$ oppure $w_i = \frac{1}{2m}$ se $(x_i, y_i) \in N$, dove $l = \#(P)$ ed $m = \#(N)$ (numero degli esempi positivi e numero degli esempi negativi).

                Sia inoltre $n := \#(D) = \#(P) + \#(N) = l + m$.

                \item \emph{For} $t = [1:T]$
                \begin{enumerate}
                    \item Si normalizzano i pesi, in modo che la loro somma sia pari ad 1:
                    $$ w_{t,i} \leftarrow \frac{w_{t,i}}{\sum_{j = 1}^{n}w_{t,j}}$$

                    \item \label{adaboost_minimum_error}
                    Si estrae il miglior classificatore debole. La procedura viene esposta nel dettaglio nella sezione \ref{sec:weak_learner}, ma si tenga presente che il miglior classificatore è quello il cui \emph{errore pesato} è minimo per la corrente iterazione.
                    $$ \epsilon_t = \min_{f,p,\theta} \{
                    \sum_{i = 1}^{n} w_{t,i} \cdot |h(x_i, f, p, \theta) - y_i|
                    \} $$
                    Siano inoltre $f_t$, $p_t$, $\theta_t$ i parametri del classificatore debole che ne minimizzano l'errore pesato:
                    $$ h_t(x) := h(x, f_t, p_t, \theta_t) $$

                    \item \label{adaboost_beta} $\beta_t \leftarrow \frac{\epsilon_t}{1 - \epsilon_t}$

                    \item \label{adaboost_update_weights} Si aggiornano i pesi
                    $$ w_{t+1, i} \leftarrow w_{t,i} \cdot \beta_{t}^{e_i} $$
                    dove $e_i = 1$ se $(x_i, h_t(x_i)) \in D$ (ovvero se $x_i$ è classificata correttamente), $e_i = 0$ altrimenti.

                    \item $\alpha_t \leftarrow \log(\frac{1}{\beta_t})$
                \end{enumerate}

                \item \label{adaboost_strong_classifier} Il classificatore forte è dato da:
                \begin{equation}\label{eq:strong_classifier}
                    F(x) = 
                    \begin{cases}
                        1 & \text{ se } \sum_{t = 1}^{T} \alpha_t h_t(x) > \theta \sum_{t = 1}^{T} \alpha_t \\
                        0 & \text{ altrimenti }
                    \end{cases}
                \end{equation}
                dove $\theta \in [0,1]$ è la soglia.
            \end{enumerate}

            Si noti che, nel'operazione \ref{adaboost_minimum_error}, l'errore pesato non è altro che la somma dei pesi degli esempi non classificati correttamente. Infatti:
            $$ h(x_i, f, p, \theta) = y_i \Rightarrow |h(x_i, f, p, \theta) - y_i| = 0 $$
            $$ h(x_i, f, p, \theta) \neq y_i \Rightarrow |h(x_i, f, p, \theta) - y_i| = 1 $$

            Al punto \ref{adaboost_beta}, il valore di $\beta_t$ non è altro che il rapporto tra l'errore pesato del classificatore debole e la somma dei pesi delle immagini classificate correttamente. Tale valore è chiaramente $0 < \beta_t < 1$.

            In fase di aggiornamento dei pesi (punto \ref{adaboost_update_weights}), i pesi relativi ad esempi classificati correttamente vengono moltiplicati per $\beta_t$ ($\beta_{t}^{1} = \beta_t < 1$) e quindi decrementati, mentre gli altri vengono lasciati inalterati ($\beta_{t}^{0} = 1$). Fare in modo che gli esempi non classificati correttamente abbiano un peso maggiore di quelli classificati correttamente è il modo per influenzare la scelta del classificatore debole successivo che andrà a colmare le lacune del suo predecessore.

            La scelta della soglia per il classificatore forte (punto \ref{adaboost_strong_classifier}) deve minimizzare il numero di esempi classificati in modo errato.
    
    \section{\emph{Weak Learner} [Da revisionare]}
    \label{sec:weak_learner}
        \subsection{Procedura di estrazione del classificatore debole}
            Si è detto che un classificatore debole è costruito a partire da una feature di Haar. La scelta del migliore, quindi, mira ad identificare la feature, la polarità e la soglia che minimizzano l'errore pesato di classificazione.

            Si ricordi che le feature di Haar sono degli indicatori di quanto le intensità dei pixel variano da una regione della feature ad un'altra. Il classificatore debole, quindi, classificherà l'immagine a seconda che tale indice sia maggiore o minore di una certa soglia. Il compito della polarità è quello di stabilire il verso della diseguaglianza.

            Il pool di feature da testare è costituito - teoricamente - da tutte quelle individuabili nell'immagini di allenamento. Nell'opera di Viola e Jones vengono utilizzate immagini di allenamento di $24 \times 24$ pixel e 5 tipologie di feature (\cite{Viola04}, sezione 2.2): il numero di possibili features in tale area è maggiore di 160000. In questa applicazione si utilizzano immagini di $160 \times 100$ pixel e 4 tipologie di feature: il pool è costituito da un numero di elementi maggiore di almeno 4 ordini di grandezza.

            È da tener presente che moltissime di queste feature sono poco significative in questa situazione: non ha senso calcolare la variazione di intensità di due aree molto piccole con delle immagini che hanno una risoluzione tanto alta. Effettuando una prima scrematura, si cercherà di avere un pool di feature selezionabili la cui dimensione non superi quella del pool di Viola-Jones per più di un ordine di grandezza.

            Sia $\{ f_1,...,f_k\}$ l'insieme di tutte le feature selezionabili, $D = \{(x_1,y_1), ..., (x_n, y_n) \}$ l'insieme degli esempi di allenamento e $\{w_1, ..., w_n\}$ l'insieme dei relativi pesi. La scelta del classificatore debole avviene come descritto dal seguente algoritmo in pseudocodice:

            \begin{enumerate}
                \item Si calcolano $T^+$ e $T^-$, rispettivamente, somma dei pesi degli esempi negativi e di quelli negativi:
                $$T^+ \leftarrow \sum_{i = 1}^{n} (w_i y_i)
                \text{ , }
                T^- \leftarrow \sum_{i = 1}^{n} [w_i (1 - y_i)]$$

                \item \emph{For} $f = [f_1, ..., f_k]$

                \begin{enumerate}
                    \item Si inizializza una lista di $n$ elementi per memorizzare i valori della feature i-esima applicata ad ogni immagine di allenamento:
                    $$values[i] \leftarrow f(x_i) \; \forall x_i \in D$$

                    \item Si ordinano gli elementi della lista in ordine crescente. Si tenga in conto che, dopo tale operazione, all'i-esima posizione della lista non corrisponderà più il valore della feature applicata all'i-esima immagine di allenamento.

                    \item Si inizializzano $S^+$ ed $S^-$, con le quali, scorrendo gli elementi della lista con un cursore, indicheremo rispettivamente la somma dei pesi degli esempi positivi e di quelli negativi: $S^+ \leftarrow 0, S^- \leftarrow 0$

                    \item \emph{For} $i = [1:n]$

                    \begin{enumerate}
                        \item A causa del rilocamento degli indici, alla posizione i-esima della lista corrisponderà il valore della feature dell'elemento $x_j$ con classificazione $y_j$ e peso $w_j$ tale che $(x_j, y_j) \in D$:
                        $$x_j, y_j, w_j \Leftarrow values[i]$$

                        \item \emph{If} $y_i = 1$ \emph{Then}
                        \begin{enumerate}
                            \item $S^+ \leftarrow S^+ + w_j$
                        \end{enumerate}
                        \item \emph{Else}
                        \begin{enumerate}
                            \item $S^+ \leftarrow S^- + w_j$
                        \end{enumerate}

                        \item \label{best_classifier_p_theta}
                        Si calcola calcola l'errore pesato di classificazione:
                        $$e_i = \min\{ S^+ + (T^- - S^-), S^- + (T^+ - S^+) \}$$

                    \end{enumerate}

                    \item Si determinano la polarità ($p_f$) e la soglia ($\theta_f$) per cui l'errore pesato ($\epsilon_f)$ di classificazione per un classificatore che utilizza la feature $f$ è minimo:
                    $$p_f, \theta_f | \epsilon_f = \min \{ e_1, ..., e_n \}$$
                \end{enumerate}

                \item Si scelgono polarità ($p$) e soglia ($\theta$) finali, ovvero quelle del classificatore debole con errore pesato $\epsilon$ minore tra tutti i classificatori possibili:
                $$p, \theta | \epsilon = \min \{ \epsilon_1, ..., \epsilon_k \}$$
                Il miglior classificatore debole è quindi:
                \begin{equation}
                    \label{eq:weak_classifier}
                    h(x) := \begin{cases}
                    1 & \text{ se } pf(x) < p\theta \\
                    0 & \text{ altrimenti }
                \end{cases}
            \end{equation}

            \end{enumerate}

            Il metodo di identificazione della polarità e della soglia non viene riportato nell'algoritmo, essendo un passaggio che merita una trattazione a parte. Selezionare un valore di soglia vuol dire trovare il \emph{punto che partiziona al meglio la lista dei valori della feature calcolata sulle immagini di allenamento, in modo tale da minimizzare gli errori di classificazione}. La miglior soglia di una buona feature fa in modo che la maggior parte delle immagini appartenenti alla stessa classe assumano un valore minore (o maggiore). Si può notare, come diretta conseguenza, che con una feature pessima per la classificazione non sarà possibile trovare un valore di soglia che soddisfi tale criterio.

            Al punto \ref{best_classifier_p_theta} viene calcolato l'errore pesato di classificazione per una feature $f$ con soglia $values[i]$\footnote{I possibili valori delle soglie corrispondono esattamente ai valori della feature calcolata sugli esempi di allenamento}. Per essere più espliciti, bisogna effettuare una serie di osservazioni:
            \begin{enumerate}
                \item \label{obs:1} $T^+$ ($T^-$) corrisponde alla somma dei pesi degli esempi positivi (negativi);
                \item \label{obs:2} $S^+$ ($S^-$) corrisponde alla somma dei pesi degli esempi positivi (negativi) dalla prima posizione fino all'i-esima della lista (quella su cui è posizionato il cursore);
                \item \label{obs:3} $T^+ - S^+$ ($T^- - S^-$) corrisponde alla somma dei pesi degli esempi positivi (negativi) dalla posizione $i+1$ della lista fino alla fine;
                \item \label{obs:4} Per un classificatore della forma (\ref{eq:weak_classifier}) con $p = 1$, $S^+$ corrisponde alla \emph{somma dei pesi degli esempi classificati correttamente}, mentre $S^- + (T^+ - S^+)$ corrisponde alla somma dei pesi degli esempi classificati in modo scorretto;
                \item \label{obs:5} Per l'osservazione \ref{obs:4} un classificatore (\ref{eq:weak_classifier}) con $p = 1$, la quantità $S^- + (T^+ - S^+)$ è \emph{l'errore pesato};
                \item \label{obs:6} Analogamente alle osservazioni \ref{obs:4} e \ref{obs:5}, un classificatore (\ref{eq:weak_classifier}) con $p = -1$ commetterà un errore pesato pari alla quantità $S^+ + (T^- - S^-)$.
            \end{enumerate}

            Grazie alle osservazioni \ref{obs:5} e \ref{obs:6}, dal semplice calcolo dell'errore di classificazione pesato, si ottiene anche il valore della polarità:
            \begin{equation}
                p = \begin{cases}
                1 & \text{ se } S^- + (T^+ - S^+) < S^+ + (T^- - S^-) \\
                -1 & \text{ altrimenti }
            \end{cases}
            \end{equation}

        \subsection{Valutazione della complessità computazionale}
            In definitiva, con uno scorrimento della lista ordinata si ottengo i parametri per la costruzione del classificatore debole. La complessità di tale operazione è fortemente legata all'algoritmo di ordinamento della lista, la quale ha $\Theta(n\log n)$ come limite teorico inferiore \cite[p. 167]{Cormen09}. Nell'implementazione è stato scelto proprio un algoritmo che avesse complessità $\Omega(n\log n)$ nel caso peggiore. Ripetendo queste operazioni per ognuna delle feature selezionabili, si ottiene che l'algoritmo di selezione del miglior classificatore debole ha complessità $\Theta(kn\log n)$.
